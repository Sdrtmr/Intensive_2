{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_9804\\1135642139.py:9: DtypeWarning: Columns (51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,87,88,89,91,95,96,97,99,131,132,133,135,136,140,141,142,144,145,146,147,148,151,152,155,156,157,159,160,163,164,165,167,168,172,173,174,175,176,177,178,183,184,185,186,187,188,189,192,193,194,195,196,197,203,204,207,211,212,215,239,240,241,243,244,245,459,467,515,523,531,539,547,555,563,567,571,575,579,580,583,587,595,603,611,612,795,799,1031,1032,1033,1034,1035,1036,1037,1039,1047,1055,1063,1071,1072,1177,1178,1179,1180,1181,1182,1277,1278,1281,1282,1447,1448,1449,1450,1451,1452,1453,1454,1653,1654,1656,2193,2194,2199) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(filepath)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.5005684\ttest: 0.5017623\tbest: 0.5017623 (0)\ttotal: 2.85s\tremaining: 2h 19m 14s\n",
      "100:\tlearn: 0.0338261\ttest: 0.0744067\tbest: 0.0725854 (24)\ttotal: 2m 55s\tremaining: 1h 22m 15s\n",
      "200:\tlearn: 0.0160508\ttest: 0.0758867\tbest: 0.0725854 (24)\ttotal: 6m 39s\tremaining: 1h 30m 25s\n",
      "300:\tlearn: 0.0099111\ttest: 0.0803244\tbest: 0.0725854 (24)\ttotal: 9m 53s\tremaining: 1h 26m 33s\n",
      "400:\tlearn: 0.0047676\ttest: 0.0824088\tbest: 0.0725854 (24)\ttotal: 13m 4s\tremaining: 1h 22m 33s\n",
      "500:\tlearn: 0.0032023\ttest: 0.0852146\tbest: 0.0725854 (24)\ttotal: 16m 37s\tremaining: 1h 20m 41s\n",
      "600:\tlearn: 0.0024371\ttest: 0.0874703\tbest: 0.0725854 (24)\ttotal: 19m 49s\tremaining: 1h 16m 59s\n",
      "700:\tlearn: 0.0019952\ttest: 0.0895126\tbest: 0.0725854 (24)\ttotal: 22m 57s\tremaining: 1h 13m 9s\n",
      "800:\tlearn: 0.0016578\ttest: 0.0912989\tbest: 0.0725854 (24)\ttotal: 26m 22s\tremaining: 1h 10m 12s\n",
      "900:\tlearn: 0.0014202\ttest: 0.0929786\tbest: 0.0725854 (24)\ttotal: 29m 32s\tremaining: 1h 6m 38s\n",
      "1000:\tlearn: 0.0012608\ttest: 0.0946140\tbest: 0.0725854 (24)\ttotal: 32m 38s\tremaining: 1h 3m 2s\n",
      "1100:\tlearn: 0.0011396\ttest: 0.0955836\tbest: 0.0725854 (24)\ttotal: 35m 46s\tremaining: 59m 33s\n",
      "1200:\tlearn: 0.0010373\ttest: 0.0967911\tbest: 0.0725854 (24)\ttotal: 38m 55s\tremaining: 56m 10s\n",
      "1300:\tlearn: 0.0009471\ttest: 0.0979407\tbest: 0.0725854 (24)\ttotal: 42m 9s\tremaining: 52m 55s\n",
      "1400:\tlearn: 0.0008706\ttest: 0.0990535\tbest: 0.0725854 (24)\ttotal: 45m 28s\tremaining: 49m 45s\n",
      "1500:\tlearn: 0.0007954\ttest: 0.1002194\tbest: 0.0725854 (24)\ttotal: 48m 42s\tremaining: 46m 30s\n",
      "1600:\tlearn: 0.0007325\ttest: 0.1010514\tbest: 0.0725854 (24)\ttotal: 51m 53s\tremaining: 43m 12s\n",
      "1700:\tlearn: 0.0006880\ttest: 0.1019493\tbest: 0.0725854 (24)\ttotal: 55m 11s\tremaining: 40m\n",
      "1800:\tlearn: 0.0006449\ttest: 0.1026917\tbest: 0.0725854 (24)\ttotal: 58m 27s\tremaining: 36m 46s\n",
      "1900:\tlearn: 0.0006117\ttest: 0.1031942\tbest: 0.0725854 (24)\ttotal: 1h 1m 39s\tremaining: 33m 30s\n",
      "2000:\tlearn: 0.0005723\ttest: 0.1039335\tbest: 0.0725854 (24)\ttotal: 1h 4m 49s\tremaining: 30m 13s\n",
      "2100:\tlearn: 0.0005503\ttest: 0.1044789\tbest: 0.0725854 (24)\ttotal: 1h 8m 3s\tremaining: 26m 58s\n",
      "2200:\tlearn: 0.0005194\ttest: 0.1053698\tbest: 0.0725854 (24)\ttotal: 1h 10m 51s\tremaining: 23m 35s\n",
      "2300:\tlearn: 0.0004914\ttest: 0.1061559\tbest: 0.0725854 (24)\ttotal: 1h 13m 43s\tremaining: 20m 16s\n",
      "2400:\tlearn: 0.0004724\ttest: 0.1065786\tbest: 0.0725854 (24)\ttotal: 1h 16m 48s\tremaining: 17m 2s\n",
      "2500:\tlearn: 0.0004585\ttest: 0.1069537\tbest: 0.0725854 (24)\ttotal: 1h 19m 56s\tremaining: 13m 50s\n",
      "2600:\tlearn: 0.0004434\ttest: 0.1073731\tbest: 0.0725854 (24)\ttotal: 1h 22m 56s\tremaining: 10m 37s\n",
      "2700:\tlearn: 0.0004304\ttest: 0.1076628\tbest: 0.0725854 (24)\ttotal: 1h 26m 16s\tremaining: 7m 26s\n",
      "2800:\tlearn: 0.0004175\ttest: 0.1080329\tbest: 0.0725854 (24)\ttotal: 1h 29m 22s\tremaining: 4m 14s\n",
      "2900:\tlearn: 0.0004057\ttest: 0.1083090\tbest: 0.0725854 (24)\ttotal: 1h 32m 24s\tremaining: 1m 3s\n",
      "2933:\tlearn: 0.0004007\ttest: 0.1085552\tbest: 0.0725854 (24)\ttotal: 1h 33m 41s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.07258538277\n",
      "bestIteration = 24\n",
      "\n",
      "Shrink model to first 25 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained successfully.\n",
      "Evaluation Metrics: {'accuracy': 0.9863713798977853, 'roc_auc': 0.5363773747841106, 'classification_report': '              precision    recall  f1-score   support\\n\\n           0       0.99      1.00      0.99       579\\n           1       0.00      0.00      0.00         8\\n\\n    accuracy                           0.99       587\\n   macro avg       0.49      0.50      0.50       587\\nweighted avg       0.97      0.99      0.98       587\\n'}\n",
      "Probabilities: [0.01422786 0.01157046 0.01400227 0.01325636 0.01325636 0.01325636\n",
      " 0.01146399 0.01379043 0.01325636 0.01325636 0.01325636 0.01325636\n",
      " 0.05448642 0.01325636 0.01325636 0.01325636 0.01325636 0.01325636\n",
      " 0.01931597 0.01422786 0.01325636 0.01575194 0.01325636 0.01585191\n",
      " 0.01325636 0.01375559 0.01325636 0.01936911 0.01277656 0.01325636\n",
      " 0.01325636 0.01367126 0.01325636 0.01151525 0.01455407 0.01325636\n",
      " 0.01325636 0.01325636 0.01585191 0.01422786 0.01538146 0.01498338\n",
      " 0.01325636 0.01325636 0.01325636 0.01325636 0.01325636 0.0139917\n",
      " 0.01325636 0.01367126 0.01325636 0.01561347 0.01325636 0.01781421\n",
      " 0.01194812 0.01325636 0.01325636 0.01317254 0.01401351 0.01325636\n",
      " 0.01325636 0.0139917  0.01325636 0.01422786 0.01325636 0.01325636\n",
      " 0.0139917  0.02157839 0.01734126 0.01325636 0.01325636 0.01367126\n",
      " 0.01585191 0.01422786 0.01325636 0.01508847 0.0139917  0.01515618\n",
      " 0.01286501 0.01325636 0.01325636 0.01325636 0.01332382 0.01295445\n",
      " 0.01325636 0.01585191 0.01325636 0.01325636 0.01422786 0.01325636\n",
      " 0.07109157 0.01422786 0.01325636 0.01329919 0.01325636 0.01423232\n",
      " 0.01558921 0.01325636 0.01325636 0.01422786 0.01325636 0.01084278\n",
      " 0.01503047 0.01325636 0.01143532 0.01325636 0.01325636 0.01325636\n",
      " 0.01467272 0.01325636 0.01325636 0.01325636 0.01325636 0.01325636\n",
      " 0.01085256 0.03338011 0.01423232 0.01422786 0.01325636 0.01325636\n",
      " 0.01446523 0.01422786 0.01834291 0.01422786 0.01325636 0.01422786\n",
      " 0.01325636 0.01317254 0.01429188 0.0139244  0.01325636 0.014984\n",
      " 0.01325636 0.01441421 0.01599239 0.01026565 0.01325636 0.01325636\n",
      " 0.01325636 0.01032633 0.01325636 0.00777576 0.01325636 0.01325636\n",
      " 0.01325636 0.01367126 0.01325636 0.01325636 0.10952153 0.0139917\n",
      " 0.01325636 0.01585191 0.01325636 0.01422786 0.01325636 0.01245637\n",
      " 0.01422786 0.01325636 0.01422786 0.01325636 0.02131899 0.01585191\n",
      " 0.01195398 0.01325636 0.01585191 0.01880342 0.0183564  0.01325636\n",
      " 0.01401351 0.01325636 0.01325636 0.01422786 0.00990736 0.03302791\n",
      " 0.01439802 0.01325636 0.01325636 0.01325636 0.01325636 0.01325636\n",
      " 0.0139917  0.01325636 0.01325636 0.01325636 0.01619979 0.01529832\n",
      " 0.01325636 0.01325636 0.01325636 0.01532172 0.01325636 0.01325636\n",
      " 0.01317254 0.01325636 0.01325636 0.01422786 0.01325636 0.01325636\n",
      " 0.01501627 0.01325636 0.01367126 0.01325636 0.01422786 0.01325636\n",
      " 0.01367126 0.01325636 0.0139917  0.01325636 0.01325636 0.01158197\n",
      " 0.01585191 0.01325636 0.01325636 0.01325636 0.01325636 0.01585191\n",
      " 0.01325636 0.01325636 0.01325636 0.01354743 0.01325636 0.01422786\n",
      " 0.01325636 0.01437617 0.01206556 0.01477117 0.01460781 0.01325636\n",
      " 0.01501627 0.0251709  0.01325636 0.01325636 0.01310979 0.01325636\n",
      " 0.01325636 0.01325636 0.01422786 0.01006869 0.02569004 0.01325636\n",
      " 0.01501627 0.01325636 0.01325636 0.01325636 0.01477117 0.01325636\n",
      " 0.01325636 0.01422786 0.01325636 0.01325636 0.01585191 0.01325636\n",
      " 0.01675479 0.01325636 0.01285718 0.01477117 0.01325636 0.01325636\n",
      " 0.01422786 0.01585191 0.01325636 0.01325636 0.01413799 0.01325636\n",
      " 0.01325636 0.01401351 0.01325636 0.03508716 0.01325636 0.01286482\n",
      " 0.01317254 0.01325636 0.01325636 0.01672878 0.01621159 0.01446523\n",
      " 0.01422786 0.01220578 0.01325636 0.01325636 0.01325636 0.01325636\n",
      " 0.01154194 0.01059232 0.01501627 0.01501627 0.01690566 0.01422786\n",
      " 0.01325636 0.01325636 0.01367126 0.01464822 0.01325636 0.01192151\n",
      " 0.01606906 0.01325636 0.016734   0.01785754 0.01325636 0.01205506\n",
      " 0.01325636 0.01325636 0.01159403 0.01325636 0.01325636 0.01325636\n",
      " 0.01325636 0.01325636 0.01376502 0.01325636 0.01167496 0.01422786\n",
      " 0.01325636 0.01325636 0.01642337 0.01325636 0.01445095 0.01489504\n",
      " 0.01325636 0.01150948 0.01743899 0.01325406 0.01325636 0.00953529\n",
      " 0.01325636 0.01325636 0.01325636 0.01477117 0.01325636 0.01345029\n",
      " 0.02459001 0.01325636 0.01325636 0.02929596 0.01422786 0.01325636\n",
      " 0.01501627 0.01325636 0.01325636 0.01585191 0.01422786 0.01325636\n",
      " 0.01325636 0.01325636 0.01325636 0.01325636 0.01467272 0.01163949\n",
      " 0.01575194 0.01325636 0.01422786 0.01325636 0.01325636 0.01325636\n",
      " 0.01422786 0.01566865 0.02212963 0.01325636 0.06257592 0.01325636\n",
      " 0.01325636 0.01422786 0.01133554 0.01672878 0.01477117 0.01325636\n",
      " 0.01317254 0.01325636 0.01422786 0.01338951 0.01325636 0.01367126\n",
      " 0.01325636 0.01422786 0.01325636 0.01422786 0.01325636 0.01325636\n",
      " 0.01325636 0.01325636 0.01325636 0.01358486 0.01325636 0.01558921\n",
      " 0.01336283 0.01422786 0.01467792 0.01813376 0.01325636 0.01477117\n",
      " 0.01367126 0.01325636 0.01278898 0.01467272 0.01174381 0.01422786\n",
      " 0.01325636 0.01422786 0.01325636 0.01367126 0.01292642 0.01458528\n",
      " 0.01325636 0.01325636 0.01401351 0.01422786 0.01335428 0.01054728\n",
      " 0.01422786 0.01422786 0.01501627 0.01325636 0.01367126 0.01367126\n",
      " 0.01399608 0.01325636 0.01325636 0.01325636 0.01627179 0.01325636\n",
      " 0.01490039 0.01325636 0.01325636 0.01325636 0.01325636 0.01325636\n",
      " 0.00953896 0.01325636 0.01325636 0.01325636 0.01477117 0.01325636\n",
      " 0.01360844 0.01325636 0.01325636 0.01422786 0.01360844 0.01325636\n",
      " 0.01325636 0.01406755 0.01325636 0.01325636 0.01501627 0.01367126\n",
      " 0.01190838 0.01886796 0.01422786 0.01422786 0.01585191 0.01422786\n",
      " 0.01387408 0.01422786 0.01367126 0.01672878 0.01367126 0.01237493\n",
      " 0.01325636 0.01704204 0.01325636 0.01477117 0.01501627 0.01325636\n",
      " 0.01325636 0.01317254 0.01325636 0.01325636 0.01501627 0.01325636\n",
      " 0.01325636 0.01477117 0.01194515 0.01367126 0.0139917  0.01325636\n",
      " 0.01325636 0.01501627 0.02988695 0.01672878 0.01354365 0.0139132\n",
      " 0.01325636 0.01145455 0.01325636 0.01325636 0.01268681 0.01460479\n",
      " 0.01548539 0.01589682 0.02480778 0.01325636 0.01325636 0.01325636\n",
      " 0.01367126 0.01523708 0.01325636 0.01561347 0.01237836 0.01292642\n",
      " 0.01367126 0.01325636 0.01789078 0.01325636 0.01325636 0.01363682\n",
      " 0.01325636 0.01616138 0.01325636 0.01694952 0.02058865 0.01431216\n",
      " 0.01325636 0.01386773 0.01325636 0.01522858 0.01423232 0.01325636\n",
      " 0.01200373 0.01422786 0.01360844 0.01422786 0.01325636 0.01325636\n",
      " 0.01325636 0.01325636 0.01535629 0.01906867 0.01325636 0.01325636\n",
      " 0.01778004 0.01422786 0.0139917  0.01599239 0.01413799 0.01325636\n",
      " 0.01422786 0.01325636 0.01325636 0.01422786 0.01325636 0.01325636\n",
      " 0.01325636 0.01325636 0.01076791 0.01195398 0.01477117 0.01292642\n",
      " 0.01325636 0.01325636 0.01317254 0.01325636 0.01779661 0.01526968\n",
      " 0.02395897 0.01477117 0.01325636 0.01325636 0.01325636 0.00898811\n",
      " 0.01325636 0.01477117 0.01422786 0.01325636 0.01325636 0.01422786\n",
      " 0.01325636 0.01325636 0.05903563 0.01325636 0.01730347 0.01185507\n",
      " 0.01325636 0.01354365 0.01367126 0.01325636 0.01325636 0.0139917\n",
      " 0.00846832 0.02110309 0.03906677 0.02042693 0.01325636 0.01325636\n",
      " 0.01325636 0.01325636 0.01325636 0.01157046 0.01325636]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score\n",
    "import numpy as np\n",
    "\n",
    "def predict_parking_purchase_probability_catboost(filepath, client_id_col='client_id', target_col='target', test_size=0.2, random_state=42):\n",
    "    try:\n",
    "        df = pd.read_csv(filepath)\n",
    "\n",
    "        if client_id_col not in df.columns or target_col not in df.columns:\n",
    "            print(f\"Error: Columns '{client_id_col}' and '{target_col}' not found in '{filepath}'.\")\n",
    "            return None, None, None\n",
    "\n",
    "        # Separate features and target\n",
    "        X = df.drop(columns=[client_id_col, target_col])\n",
    "        y = df[target_col]\n",
    "\n",
    "        # Identify categorical features and handle potential numerical values in categorical columns.\n",
    "        categorical_features = X.select_dtypes(include=['object', 'category']).columns\n",
    "        for col in categorical_features:\n",
    "            #Convert to string if not already string, handle NaNs, and ensure no numeric values\n",
    "            if X[col].dtype != 'object':\n",
    "                X[col] = X[col].astype(str)\n",
    "            X[col] = X[col].fillna('Unknown')\n",
    "            #If any values are numbers after above changes, force them to strings.\n",
    "            X[col] = X[col].apply(lambda x: str(x) if isinstance(x, (int, float)) else x )\n",
    "\n",
    "\n",
    "        # Get indices of categorical features for CatBoost\n",
    "        categorical_features_indices = np.where(X.dtypes == 'object')[0]\n",
    "\n",
    "        # Split data\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "\n",
    "        # Initialize and train the CatBoost model\n",
    "        model = CatBoostClassifier(iterations=2934,\n",
    "                                   learning_rate=0.1,\n",
    "                                   loss_function='Logloss',\n",
    "                                   random_seed=random_state,\n",
    "                                   verbose=100,\n",
    "                                   early_stopping_rounds=2934)\n",
    "\n",
    "        model.fit(X_train, y_train, cat_features=categorical_features_indices, eval_set=(X_test, y_test))\n",
    "\n",
    "        # Make predictions (probabilities)\n",
    "        probabilities = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "        # Evaluate the model\n",
    "        accuracy = accuracy_score(y_test, model.predict(X_test))\n",
    "        roc_auc = roc_auc_score(y_test, probabilities)\n",
    "        report = classification_report(y_test, model.predict(X_test))\n",
    "\n",
    "        evaluation_metrics = {\n",
    "            \"accuracy\": accuracy,\n",
    "            \"roc_auc\": roc_auc,\n",
    "            \"classification_report\": report\n",
    "        }\n",
    "\n",
    "        return model, probabilities, evaluation_metrics\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File '{filepath}' not found.\")\n",
    "        return None, None, None\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "        return None, None, None\n",
    "\n",
    "# Example Usage (Remember to replace 'your_file.csv' with your actual file path)\n",
    "filepath = 'valid_data_clients.csv'\n",
    "model, probabilities, evaluation_metrics = predict_parking_purchase_probability_catboost(filepath)\n",
    "\n",
    "if model:\n",
    "    print(\"Model trained successfully.\")\n",
    "    print(\"Evaluation Metrics:\", evaluation_metrics)\n",
    "    print(\"Probabilities:\", probabilities)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
